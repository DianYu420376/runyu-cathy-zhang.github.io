---
layout: archive
title: "Research Topics"
permalink: /research/
author_profile: true
---

Topic 1: Distributed Control of Network Systems
----
<p align="center">
<img src="https://dianyu420376.github.io/runyu-cathy-zhang.github.io/images/distributed-control.png" alt="distributed-control-illustration" width="700" height="auto">
</p>

Limited by the sensing and communication capability, in many multi-agent systems, agents must decide their local actions based on local information. This calls for the design of distributed local rules for individual agents to achieve desirable global behavior.
In this setting, it is 

### Selected publications:


<div style="display: flex; align-items: center;">
    <img src="https://example.com/path-to-your-image.jpg" alt="Description of Picture A" style="width: 200px; height: auto;">
    <p style="margin-left: 20px;">

- [Scalable Reinforcement Learning for Linear-Quadratic Control of Networks
](https://arxiv.org/abs/2401.16183) <br> Johan Olsson, **Runyu Zhang**, Emma Tegling, Na Li
 <br> *American Control Conference (ACC), 2024*
- [On the Optimal Control of Network LQR with Spatially-exponential Decaying
Structure](https://arxiv.org/abs/2209.14376)<br>  **Runyu Zhang**, Weiyu Li, Na Li <br> *American Control Conference (ACC), 2023* (Preparing for Journal Submission)

</p>
</div>

<div style="display: flex; align-items: center;">
    <img src="https://example.com/path-to-your-image.jpg" alt="drone gif" style="width: 200px; height: auto;">
    <p style="margin-left: 20px;">

- [Scalable Reinforcement Learning for Linear-Quadratic Control of Networks
](https://arxiv.org/abs/2401.16183) <br> Johan Olsson, **Runyu Zhang**, Emma Tegling, Na Li
 <br> *American Control Conference (ACC), 2024*
- [On the Optimal Control of Network LQR with Spatially-exponential Decaying
Structure](https://arxiv.org/abs/2209.14376)<br>  **Runyu Zhang**, Weiyu Li, Na Li <br> *American Control Conference (ACC), 2023* (Preparing for Journal Submission)

</p>
</div>


Topic 2: Mutli-agent Reinforcement Learning
----


Topic 3:  Robust/Risk-sensitive Reinforcement Learning
----

